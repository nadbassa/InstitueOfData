{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "Nji1a9ULLtCA"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lab 8.5: Text Classification\n",
    "INSTRUCTIONS:\n",
    "- Run the cells\n",
    "- Observe and understand the results\n",
    "- Answer the questions"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "fnsX1AWKLtCE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import libraries"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "6pm8PttyLtCI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "## Import Libraries\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "import string\r\n",
    "import spacy\r\n",
    "\r\n",
    "from collections import Counter\r\n",
    "\r\n",
    "from sklearn.decomposition import LatentDirichletAllocation\r\n",
    "from sklearn.ensemble import GradientBoostingClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "from sklearn.svm import LinearSVC\r\n",
    "\r\n",
    "# import warnings\r\n",
    "# warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:38:33.182995Z",
     "start_time": "2019-06-17T01:38:30.045388Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "EUANiH6zLtCK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "58bUNQA0LtCV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sample:\n",
    "\n",
    "    __label__2 Stuning even for the non-gamer: This sound ...\n",
    "    __label__2 The best soundtrack ever to anything.: I'm ...\n",
    "    __label__2 Amazing!: This soundtrack is my favorite m ...\n",
    "    __label__2 Excellent Soundtrack: I truly like this so ...\n",
    "    __label__2 Remember, Pull Your Jaw Off The Floor Afte ...\n",
    "    __label__2 an absolute masterpiece: I am quite sure a ...\n",
    "    __label__1 Buyer beware: This is a self-published boo ...\n",
    "    . . .\n",
    "    \n",
    "There are only two **labels**:\n",
    "- `__label__1`\n",
    "- `__label__2`"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "UqU7d_qcLtCX"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "## Loading the data\r\n",
    "\r\n",
    "trainDF = pd.read_fwf(\r\n",
    "    filepath_or_buffer = 'C:/Users/nadun/Documents/InstitueOfData//DATA/corpus.txt',\r\n",
    "    colspecs = [(9, 10),   # label: get only the numbers 1 or 2\r\n",
    "                (11, 9000) # text: makes the it big enought to get to the end of the line\r\n",
    "               ], \r\n",
    "    header = 0,\r\n",
    "    names = ['label', 'text'],\r\n",
    "    lineterminator = '\\n'\r\n",
    ")\r\n",
    "\r\n",
    "# convert label from [1, 2] to [0, 1]\r\n",
    "trainDF['label'] = trainDF['label'] - 1"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:38:42.024845Z",
     "start_time": "2019-06-17T01:38:41.896098Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "rwWFJprZLtCZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inspect the data"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "mILVIHomLtCf"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# ANSWER\r\n",
    "trainDF.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>an absolute masterpiece: I am quite sure any o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  The best soundtrack ever to anything.: I'm rea...\n",
       "1      1  Amazing!: This soundtrack is my favorite music...\n",
       "2      1  Excellent Soundtrack: I truly like this soundt...\n",
       "3      1  Remember, Pull Your Jaw Off The Floor After He...\n",
       "4      1  an absolute masterpiece: I am quite sure any o..."
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:39:24.213192Z",
     "start_time": "2019-06-17T01:39:24.209202Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "G9_8RbOeLtCh"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "trainDF.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9999 entries, 0 to 9998\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   9999 non-null   int64 \n",
      " 1   text    9999 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "trainDF.sample(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>0</td>\n",
       "      <td>Doesn't work in anything I put it in.: I have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>Very fun and educational: Trains, shapes and p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7288</th>\n",
       "      <td>1</td>\n",
       "      <td>Disturbing...: One of the signs of a great boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9725</th>\n",
       "      <td>0</td>\n",
       "      <td>ok game: Donald Trump's Real Estate Tycoon is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>0</td>\n",
       "      <td>These are not the books you grew up with...: M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "3951      0  Doesn't work in anything I put it in.: I have ...\n",
       "95        1  Very fun and educational: Trains, shapes and p...\n",
       "7288      1  Disturbing...: One of the signs of a great boo...\n",
       "9725      0  ok game: Donald Trump's Real Estate Tycoon is ...\n",
       "3199      0  These are not the books you grew up with...: M..."
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "X = trainDF.text\r\n",
    "y = trainDF.label"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split the data into train and test"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "6YmYgG2pLtCu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "## ANSWER\r\n",
    "## split the dataset\r\n",
    "\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(\r\n",
    "    X,\r\n",
    "    y, \r\n",
    "    test_size = 0.2,\r\n",
    "    random_state = 42\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:39:40.103737Z",
     "start_time": "2019-06-17T01:39:40.100739Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "j5vErjWFLtCy"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Engineering"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "6nUp6oDOLtC1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Count Vectors as features"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "fKd9yTnyLtC2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# create a count vectorizer object\r\n",
    "count_vect = CountVectorizer(token_pattern = r'\\w{1,}')\r\n",
    "\r\n",
    "# Learn a vocabulary dictionary of all tokens in the raw documents\r\n",
    "count_vect.fit(trainDF['text'])\r\n",
    "\r\n",
    "# Transform documents to document-term matrix.\r\n",
    "X_train_count = count_vect.transform(X_train)\r\n",
    "X_test_count = count_vect.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:40:32.674674Z",
     "start_time": "2019-06-17T01:40:31.098889Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "DU2RqqDjLtC3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TF-IDF Vectors as features\n",
    "- Word level\n",
    "- N-Gram level\n",
    "- Character level"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "dJs6al0ILtC5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "%%time\r\n",
    "# word level tf-idf\r\n",
    "tfidf_vect = TfidfVectorizer(analyzer = 'word',\r\n",
    "                             token_pattern = r'\\w{1,}',\r\n",
    "                             max_features = 5000)\r\n",
    "print(tfidf_vect)\r\n",
    "\r\n",
    "tfidf_vect.fit(trainDF['text'])\r\n",
    "X_train_tfidf = tfidf_vect.transform(X_train)\r\n",
    "X_test_tfidf  = tfidf_vect.transform(X_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TfidfVectorizer(max_features=5000, token_pattern='\\\\w{1,}')\n",
      "Wall time: 1.73 s\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:40:36.088730Z",
     "start_time": "2019-06-17T01:40:34.519925Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "myjfdfP_LtC6",
    "outputId": "8bc4d529-1f66-4836-acd1-07633c29fd02"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "%%time\r\n",
    "# ngram level tf-idf\r\n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer = 'word',\r\n",
    "                                   token_pattern = r'\\w{1,}',\r\n",
    "                                   ngram_range = (2, 3),\r\n",
    "                                   max_features = 5000)\r\n",
    "print(tfidf_vect_ngram)\r\n",
    "\r\n",
    "tfidf_vect_ngram.fit(trainDF['text'])\r\n",
    "X_train_tfidf_ngram = tfidf_vect_ngram.transform(X_train)\r\n",
    "X_test_tfidf_ngram  = tfidf_vect_ngram.transform(X_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TfidfVectorizer(max_features=5000, ngram_range=(2, 3), token_pattern='\\\\w{1,}')\n",
      "Wall time: 8.75 s\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:40:57.505221Z",
     "start_time": "2019-06-17T01:40:49.387393Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-h16dUaVLtC_",
    "outputId": "3be1f8f5-670e-4249-8522-50509c8898a0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "type(X_train_tfidf_ngram)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "%%time\r\n",
    "# characters level tf-idf\r\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer = 'char',\r\n",
    "                                         token_pattern = r'\\w{1,}',\r\n",
    "                                         ngram_range = (2, 3),\r\n",
    "                                         max_features = 5000)\r\n",
    "print(tfidf_vect_ngram_chars)\r\n",
    "\r\n",
    "tfidf_vect_ngram_chars.fit(trainDF['text'])\r\n",
    "X_train_tfidf_ngram_chars = tfidf_vect_ngram_chars.transform(X_train)\r\n",
    "X_test_tfidf_ngram_chars  = tfidf_vect_ngram_chars.transform(X_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TfidfVectorizer(analyzer='char', max_features=5000, ngram_range=(2, 3),\n",
      "                token_pattern='\\\\w{1,}')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\Env_DL\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:506: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:41:10.209071Z",
     "start_time": "2019-06-17T01:40:59.211484Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Y7rmIt49LtDC",
    "outputId": "8f600e7c-b4df-4d89-bfb9-96c8436aa5ef"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Text / NLP based features\n",
    "\n",
    "Create some other features.\n",
    "\n",
    "Char_Count = Number of Characters in Text\n",
    "\n",
    "Word Count = Number of Words in Text\n",
    "\n",
    "Word Density = Average Number of Char in Words\n",
    "\n",
    "Punctuation Count = Number of Punctuation in Text\n",
    "\n",
    "Title Word Count = Number of Words in Title\n",
    "\n",
    "Uppercase Word Count = Number of Upperwords in Text"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "_Pck1cuvLtDH"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "trainDF.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>an absolute masterpiece: I am quite sure any o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  The best soundtrack ever to anything.: I'm rea...\n",
       "1      1  Amazing!: This soundtrack is my favorite music...\n",
       "2      1  Excellent Soundtrack: I truly like this soundt...\n",
       "3      1  Remember, Pull Your Jaw Off The Floor After He...\n",
       "4      1  an absolute masterpiece: I am quite sure any o..."
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "len(trainDF.text[0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "760"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "trainDF.text[0].split()[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['The', 'best', 'soundtrack', 'ever', 'to']"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "len(trainDF.text[0].split())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "trainDF.text[0].istitle()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "%%time\r\n",
    "# ANSWER\r\n",
    "trainDF['char_count'] = trainDF['text'].apply(len)\r\n",
    "trainDF['word_count'] = trainDF['text'].apply(lambda x: len(x.split()))\r\n",
    "trainDF['word_density'] = trainDF['char_count'] / (trainDF['word_count'] + 1)\r\n",
    "trainDF['punctuation_count'] = trainDF['text'].apply(lambda x: len(''.join(_ for _ in x if _ in string.punctuation))) \r\n",
    "trainDF['title_word_count'] = trainDF['text'].apply(lambda x: len([w for w in x.split() if w.istitle()]))\r\n",
    "trainDF['uppercase_word_count'] = trainDF['text'].apply(lambda x: len([w for w in x.split() if w.isupper()]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 797 ms\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "trainDF.sample(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>uppercase_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>1</td>\n",
       "      <td>YOU HAVE ANOTHER WINNER..... CONGRATULATIONS: ...</td>\n",
       "      <td>596</td>\n",
       "      <td>102</td>\n",
       "      <td>5.786408</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6614</th>\n",
       "      <td>0</td>\n",
       "      <td>Problems with drivers and Syncing - Don't Buy:...</td>\n",
       "      <td>300</td>\n",
       "      <td>53</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6781</th>\n",
       "      <td>1</td>\n",
       "      <td>Wow, Great CD!: I've been a SCOTS fan a long t...</td>\n",
       "      <td>870</td>\n",
       "      <td>158</td>\n",
       "      <td>5.471698</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5060</th>\n",
       "      <td>0</td>\n",
       "      <td>Not new ,disappointed: I was surprised to see ...</td>\n",
       "      <td>134</td>\n",
       "      <td>25</td>\n",
       "      <td>5.153846</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6839</th>\n",
       "      <td>1</td>\n",
       "      <td>so far so good...: i'm reading this book in my...</td>\n",
       "      <td>395</td>\n",
       "      <td>81</td>\n",
       "      <td>4.817073</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  char_count  \\\n",
       "357       1  YOU HAVE ANOTHER WINNER..... CONGRATULATIONS: ...         596   \n",
       "6614      0  Problems with drivers and Syncing - Don't Buy:...         300   \n",
       "6781      1  Wow, Great CD!: I've been a SCOTS fan a long t...         870   \n",
       "5060      0  Not new ,disappointed: I was surprised to see ...         134   \n",
       "6839      1  so far so good...: i'm reading this book in my...         395   \n",
       "\n",
       "      word_count  word_density  punctuation_count  title_word_count  \\\n",
       "357          102      5.786408                 37                 2   \n",
       "6614          53      5.555556                 13                 7   \n",
       "6781         158      5.471698                 32                27   \n",
       "5060          25      5.153846                  5                 4   \n",
       "6839          81      4.817073                 22                 0   \n",
       "\n",
       "      uppercase_word_count  \n",
       "357                     98  \n",
       "6614                     4  \n",
       "6781                     6  \n",
       "5060                     1  \n",
       "6839                     0  "
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "## load spaCy\r\n",
    "nlp = spacy.load('en_core_web_sm')"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:44:03.442730Z",
     "start_time": "2019-06-17T01:44:02.298791Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Z-l2iZcLLtDO",
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Part of Speech in **SpaCy**\n",
    "\n",
    "    POS   DESCRIPTION               EXAMPLES\n",
    "    ----- ------------------------- ---------------------------------------------\n",
    "    ADJ   adjective                 big, old, green, incomprehensible, first\n",
    "    ADP   adposition                in, to, during\n",
    "    ADV   adverb                    very, tomorrow, down, where, there\n",
    "    AUX   auxiliary                 is, has (done), will (do), should (do)\n",
    "    CONJ  conjunction               and, or, but\n",
    "    CCONJ coordinating conjunction  and, or, but\n",
    "    DET   determiner                a, an, the\n",
    "    INTJ  interjection              psst, ouch, bravo, hello\n",
    "    NOUN  noun                      girl, cat, tree, air, beauty\n",
    "    NUM   numeral                   1, 2017, one, seventy-seven, IV, MMXIV\n",
    "    PART  particle                  's, not,\n",
    "    PRON  pronoun                   I, you, he, she, myself, themselves, somebody\n",
    "    PROPN proper noun               Mary, John, London, NATO, HBO\n",
    "    PUNCT punctuation               ., (, ), ?\n",
    "    SCONJ subordinating conjunction if, while, that\n",
    "    SYM   symbol                    $, %, ¬ß, ¬©, +, ‚àí, √ó, √∑, =, :), üòù\n",
    "    VERB  verb                      run, runs, running, eat, ate, eating\n",
    "    X     other                     sfpksdpsxmsa\n",
    "    SPACE space\n",
    "    \n",
    "Find out number of Adjective, Adverb, Noun, Numeric, Pronoun, Proposition, Verb.\n",
    "\n",
    "    Hint:\n",
    "    1. Convert text to spacy document\n",
    "    2. Use pos_\n",
    "    3. Use Counter "
   ],
   "metadata": {
    "colab_type": "text",
    "id": "p-9d0G59LtDR"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "# Initialise some columns for feature's counts\r\n",
    "trainDF['adj_count'] = 0\r\n",
    "trainDF['adv_count'] = 0\r\n",
    "trainDF['noun_count'] = 0\r\n",
    "trainDF['num_count'] = 0\r\n",
    "trainDF['pron_count'] = 0\r\n",
    "trainDF['propn_count'] = 0\r\n",
    "trainDF['verb_count'] = 0"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:50:15.900377Z",
     "start_time": "2019-06-17T01:50:15.889406Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "NcxmvIOGLtDS"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "len(trainDF)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:52:39.611809Z",
     "start_time": "2019-06-17T01:52:39.608818Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "1KfFtu1HcPwA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "trainDF.text[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"The best soundtrack ever to anything.: I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\""
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "%%time\r\n",
    "# for each text\r\n",
    "for i in range(len(trainDF)):\r\n",
    "    # convert into a spaCy document\r\n",
    "    doc = nlp(trainDF.text[i])\r\n",
    "    # initialise feature counters\r\n",
    "    c = Counter([token.pos_ for token in doc])\r\n",
    "\r\n",
    "    trainDF.at[i, 'adj_count'] = c['ADJ']\r\n",
    "    trainDF.at[i, 'adv_count'] = c['ADV']\r\n",
    "    trainDF.at[i, 'noun_count'] = c['NOUN']\r\n",
    "    trainDF.at[i, 'num_count'] = c['NUM']\r\n",
    "    trainDF.at[i, 'pron_count'] = c['PRON']\r\n",
    "    trainDF.at[i, 'propn_count'] = c['PROPN']\r\n",
    "    trainDF.at[i, 'verb_count'] = c['VERB']"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "cols = [\r\n",
    "    'char_count', 'word_count', 'word_density',\r\n",
    "    'punctuation_count', 'title_word_count',\r\n",
    "    'uppercase_word_count', 'adj_count',\r\n",
    "    'adv_count', 'noun_count', 'num_count',\r\n",
    "    'pron_count', 'propn_count', 'verb_count']\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T01:59:42.424828Z",
     "start_time": "2019-06-17T01:59:42.390920Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "DW1_LKP2LtDX",
    "outputId": "7a5eb5fd-cae1-4e76-f95f-e0fe9f1780d8",
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "trainDF.sample(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>uppercase_word_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>num_count</th>\n",
       "      <th>pron_count</th>\n",
       "      <th>propn_count</th>\n",
       "      <th>verb_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9466</th>\n",
       "      <td>1</td>\n",
       "      <td>An Acquaintance with darkness: A young girl na...</td>\n",
       "      <td>459</td>\n",
       "      <td>90</td>\n",
       "      <td>5.043956</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>0</td>\n",
       "      <td>Can't get it to work: I used to love these roc...</td>\n",
       "      <td>526</td>\n",
       "      <td>111</td>\n",
       "      <td>4.696429</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>0</td>\n",
       "      <td>Not My Cup of Tea: I felt like I was reading a...</td>\n",
       "      <td>141</td>\n",
       "      <td>28</td>\n",
       "      <td>4.862069</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148</th>\n",
       "      <td>0</td>\n",
       "      <td>ABSOLUTE GARBAGE PRODUCT: Do not believe any o...</td>\n",
       "      <td>474</td>\n",
       "      <td>80</td>\n",
       "      <td>5.851852</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7363</th>\n",
       "      <td>0</td>\n",
       "      <td>Fahrenheit 451- Somewhat a flop: I didn't real...</td>\n",
       "      <td>884</td>\n",
       "      <td>172</td>\n",
       "      <td>5.109827</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  char_count  \\\n",
       "9466      1  An Acquaintance with darkness: A young girl na...         459   \n",
       "1881      0  Can't get it to work: I used to love these roc...         526   \n",
       "6221      0  Not My Cup of Tea: I felt like I was reading a...         141   \n",
       "3148      0  ABSOLUTE GARBAGE PRODUCT: Do not believe any o...         474   \n",
       "7363      0  Fahrenheit 451- Somewhat a flop: I didn't real...         884   \n",
       "\n",
       "      word_count  word_density  punctuation_count  title_word_count  \\\n",
       "9466          90      5.043956                 11                18   \n",
       "1881         111      4.696429                 19                11   \n",
       "6221          28      4.862069                  5                 7   \n",
       "3148          80      5.851852                 14                12   \n",
       "7363         172      5.109827                 30                23   \n",
       "\n",
       "      uppercase_word_count  adj_count  adv_count  noun_count  num_count  \\\n",
       "9466                     3          6          6          12          1   \n",
       "1881                     5          8         16          18          2   \n",
       "6221                     3          0          0           3          0   \n",
       "3148                    11         14          8          16          1   \n",
       "7363                    11         12         19          20          6   \n",
       "\n",
       "      pron_count  propn_count  verb_count  \n",
       "9466          14            7          13  \n",
       "1881          12            0          18  \n",
       "6221           5            2           5  \n",
       "3148           6            2           7  \n",
       "7363          23            9          27  "
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Topic Models as features"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "mQCAUFWYLtDb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "%%time\r\n",
    "# train a LDA Model\r\n",
    "lda_model = LatentDirichletAllocation(n_components = 20, learning_method = 'online', max_iter = 20)\r\n",
    "\r\n",
    "X_topics = lda_model.fit_transform(X_train_count)\r\n",
    "topic_word = lda_model.components_ \r\n",
    "vocab = count_vect.get_feature_names()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:27:09.442903Z",
     "start_time": "2019-06-17T02:24:45.531924Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "wg2mAlkRLtDb",
    "outputId": "323bfce4-9263-403a-9214-e9e206d5755f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "# view the topic models\r\n",
    "n_top_words = 10\r\n",
    "topic_summaries = []\r\n",
    "print('Group Top Words')\r\n",
    "print('-----', '-'*80)\r\n",
    "for i, topic_dist in enumerate(topic_word):\r\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\r\n",
    "    top_words = ' '.join(topic_words)\r\n",
    "    topic_summaries.append(top_words)\r\n",
    "    print('  %3d %s' % (i, top_words))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Group Top Words\n",
      "----- --------------------------------------------------------------------------------\n",
      "    0 la de y en el que l harry vista un\n",
      "    1 lots skin certain scanner color yoga anywhere worthy pratchett tension\n",
      "    2 sell man peace describe extras generation eight utterly jimmy inspiring\n",
      "    3 scooter anthology gameboy oriented bela eyed offend controller ditch emmons\n",
      "    4 printer version beats versions per electric seconds stage cash dubbed\n",
      "    5 these boots pair them boot shoes stephen comfortable wear gammell\n",
      "    6 fit ear size large jawbone fits use noise exam small\n",
      "    7 dialogue web tuscan 2005 hardcore captured clue stations hatebreed piper\n",
      "    8 spy varies swell archive rank rangers duo nichols qing platform\n",
      "    9 u tomcat legs 24 formula bootleg region 19 cap liner\n",
      "   10 camcorder sleeping office blah catholic zen areas heater 17 quiet\n",
      "   11 buddy paris lifetime typically partner maker achieve astrology entry mario\n",
      "   12 the i and a to it of this is in\n",
      "   13 nearly bible higgins blues techniques spanish dolly discover taught kate\n",
      "   14 camera battery card charger apple works canon memory charge digital\n",
      "   15 letter hawthorne scarlet actions et nathaniel amy wine engrossing prison\n",
      "   16 shipping edition lyrics avoid rock vocals bottle musiq mad tales\n",
      "   17 freud theaters 2006 ps inappropriate bumps emma significance pool reports\n",
      "   18 of movie his film in the effects special history acting\n",
      "   19 sea anderson titan steer shades degreez bs strings gillain penetrating\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:28:11.804475Z",
     "start_time": "2019-06-17T02:28:10.978502Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "_8dIDyHjLtDf",
    "outputId": "ea0614e2-66f1-4ddd-bff0-142cfd4fd78a"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "top_words"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'sea anderson titan steer shades degreez bs strings gillain penetrating'"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelling"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "TtfnK1jeLtDl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "## helper function\r\n",
    "\r\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid):\r\n",
    "    # fit the training dataset on the classifier\r\n",
    "    classifier.fit(feature_vector_train, label)\r\n",
    "\r\n",
    "    # predict the labels on validation dataset\r\n",
    "    predictions = classifier.predict(feature_vector_valid)\r\n",
    "\r\n",
    "    return accuracy_score(predictions, y_test)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:34:12.273365Z",
     "start_time": "2019-06-17T02:34:12.263393Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "uwVaWSyTLtDm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "# Keep the results in a dataframe\r\n",
    "results = pd.DataFrame(columns = ['Count Vectors',\r\n",
    "                                  'WordLevel TF-IDF',\r\n",
    "                                  'N-Gram Vectors',\r\n",
    "                                  'CharLevel Vectors'])"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:34:14.900001Z",
     "start_time": "2019-06-17T02:34:14.894016Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "f_onpqUkLtDo"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Naive Bayes Classifier"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "OXwLriDpLtDq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "%%time\r\n",
    "# Naive Bayes on Count Vectors\r\n",
    "accuracy1 = train_model(MultinomialNB(), X_train_count, y_train, X_test_count)\r\n",
    "print('NB, Count Vectors    : %.4f\\n' % accuracy1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NB, Count Vectors    : 0.8540\n",
      "\n",
      "Wall time: 38.4 ms\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:34:34.147043Z",
     "start_time": "2019-06-17T02:34:34.123096Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ZcU6IKyNLtDs",
    "outputId": "d2defcfb-2046-47e1-b3b6-08d6edca94f8"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "%%time\r\n",
    "# Naive Bayes on Word Level TF IDF Vectors\r\n",
    "accuracy2 = train_model(MultinomialNB(), X_train_tfidf, y_train, X_test_tfidf)\r\n",
    "print('NB, WordLevel TF-IDF : %.4f\\n' % accuracy2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NB, WordLevel TF-IDF : 0.8600\n",
      "\n",
      "Wall time: 16.2 ms\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:34:36.399812Z",
     "start_time": "2019-06-17T02:34:36.381861Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "zqEG_ByTLtDv",
    "outputId": "0ba74f49-a71c-4d59-f57b-f39f546241ce"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "%%time\r\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\r\n",
    "accuracy3 = train_model(MultinomialNB(), X_train_tfidf_ngram, y_train, X_test_tfidf_ngram)\r\n",
    "print('NB, N-Gram Vectors   : %.4f\\n' % accuracy3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NB, N-Gram Vectors   : 0.8400\n",
      "\n",
      "Wall time: 8.52 ms\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:34:39.076000Z",
     "start_time": "2019-06-17T02:34:39.059047Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "uKEEPNi8LtDy",
    "outputId": "c00cf532-c914-4670-cde5-69bf54bf7201"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "%%time\r\n",
    "# # Naive Bayes on Character Level TF IDF Vectors\r\n",
    "accuracy4 = train_model(MultinomialNB(), X_train_tfidf_ngram_chars, y_train, X_test_tfidf_ngram_chars)\r\n",
    "print('NB, CharLevel Vectors: %.4f\\n' % accuracy4)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NB, CharLevel Vectors: 0.8180\n",
      "\n",
      "Wall time: 65.4 ms\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:34:42.057019Z",
     "start_time": "2019-06-17T02:34:42.009151Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "M9aIibkBLtD0",
    "outputId": "1f52c1f4-150d-4195-f927-cb66ec41baba"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "results.loc['Na√Øve Bayes'] = {\r\n",
    "    'Count Vectors': accuracy1,\r\n",
    "    'WordLevel TF-IDF': accuracy2,\r\n",
    "    'N-Gram Vectors': accuracy3,\r\n",
    "    'CharLevel Vectors': accuracy4}"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:34:46.265712Z",
     "start_time": "2019-06-17T02:34:46.258734Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "kkrodUzCLtD3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linear Classifier"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "-2oNfajULtD4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "%%time\r\n",
    "# Linear Classifier on Count Vectors\r\n",
    "accuracy1 = train_model(LogisticRegression(solver = 'lbfgs', max_iter = 350), X_train_count, y_train, X_test_count)\r\n",
    "print('LR, Count Vectors    : %.4f\\n' % accuracy1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LR, Count Vectors    : 0.8520\n",
      "\n",
      "Wall time: 2.45 s\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:34:50.841687Z",
     "start_time": "2019-06-17T02:34:48.637032Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "OFBhhPZ6LtD4",
    "outputId": "cb5a2b19-dfc1-4b11-e698-0488ba4eae53"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "%%time\r\n",
    "# Linear Classifier on Word Level TF IDF Vectors\r\n",
    "accuracy2 = train_model(LogisticRegression(solver = 'lbfgs', max_iter = 100), X_train_tfidf, y_train, X_test_tfidf)\r\n",
    "print('LR, WordLevel TF-IDF : %.4f\\n' % accuracy2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LR, WordLevel TF-IDF : 0.8730\n",
      "\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:34:51.310433Z",
     "start_time": "2019-06-17T02:34:51.214690Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "C89hRhDiLtD6",
    "outputId": "023669b1-788f-4a1b-d282-99464e26312c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "%%time\r\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\r\n",
    "accuracy3 = train_model(LogisticRegression(solver = 'lbfgs', max_iter = 100), X_train_tfidf_ngram, y_train, X_test_tfidf_ngram)\r\n",
    "print('LR, N-Gram Vectors   : %.4f\\n' % accuracy3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LR, N-Gram Vectors   : 0.8360\n",
      "\n",
      "Wall time: 103 ms\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:34:51.749258Z",
     "start_time": "2019-06-17T02:34:51.683435Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "MvhV1jC6LtD9",
    "outputId": "9bef9b1d-2dc3-4300-c4ff-831957aadee4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "%%time\r\n",
    "# Linear Classifier on Character Level TF IDF Vectors\r\n",
    "accuracy4 = train_model(LogisticRegression(solver = 'lbfgs', max_iter = 100), X_train_tfidf_ngram_chars, y_train, X_test_tfidf_ngram_chars)\r\n",
    "print('LR, CharLevel Vectors: %.4f\\n' % accuracy4)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LR, CharLevel Vectors: 0.8485\n",
      "\n",
      "Wall time: 504 ms\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:34:52.635899Z",
     "start_time": "2019-06-17T02:34:52.175122Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "XPjIxmtKLtEA",
    "outputId": "58f4b0e9-e786-45a1-830e-5945129792d4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "results.loc['Logistic Regression'] = {\r\n",
    "    'Count Vectors': accuracy1,\r\n",
    "    'WordLevel TF-IDF': accuracy2,\r\n",
    "    'N-Gram Vectors': accuracy3,\r\n",
    "    'CharLevel Vectors': accuracy4}"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:34:53.029844Z",
     "start_time": "2019-06-17T02:34:53.018872Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ZFK_LWTcLtED"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Support Vector Machine"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "q1wYto68LtEE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "%%time\r\n",
    "# Support Vector Machine on Count Vectors\r\n",
    "accuracy1 = train_model(LinearSVC(), X_train_count, y_train, X_test_count)\r\n",
    "print('SVM, Count Vectors    : %.4f\\n' % accuracy1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVM, Count Vectors    : 0.8345\n",
      "\n",
      "Wall time: 663 ms\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:34:54.237613Z",
     "start_time": "2019-06-17T02:34:53.406835Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "yYGz8he5LtEE",
    "outputId": "546b1ea8-27c9-45bb-fd91-da08244d6796"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "%%time\r\n",
    "# Support Vector Machine on Word Level TF IDF Vectors\r\n",
    "accuracy2 = train_model(LinearSVC(), X_train_tfidf, y_train, X_test_tfidf)\r\n",
    "print('SVM, WordLevel TF-IDF : %.4f\\n' % accuracy2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVM, WordLevel TF-IDF : 0.8610\n",
      "\n",
      "Wall time: 143 ms\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:34:54.743263Z",
     "start_time": "2019-06-17T02:34:54.606629Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "wMt26K0cLtEG",
    "outputId": "406cf62d-c09d-4f9b-c298-eabce0b69238"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "%%time\r\n",
    "# Support Vector Machine on Ngram Level TF IDF Vectors\r\n",
    "accuracy3 = train_model(LinearSVC(), X_train_tfidf_ngram, y_train, X_test_tfidf_ngram)\r\n",
    "print('SVM, N-Gram Vectors   : %.4f\\n' % accuracy3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVM, N-Gram Vectors   : 0.8210\n",
      "\n",
      "Wall time: 103 ms\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:34:55.220003Z",
     "start_time": "2019-06-17T02:34:55.119256Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "eFt6Y1VvLtEI",
    "outputId": "628299db-8bca-4698-c64e-5b291bd248e1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "%%time\r\n",
    "# Support Vector Machine on Character Level TF IDF Vectors\r\n",
    "accuracy4 = train_model(LinearSVC(), X_train_tfidf_ngram_chars, y_train, X_test_tfidf_ngram_chars)\r\n",
    "print('SVM, CharLevel Vectors: %.4f\\n' % accuracy4)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVM, CharLevel Vectors: 0.8570\n",
      "\n",
      "Wall time: 518 ms\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:34:56.139528Z",
     "start_time": "2019-06-17T02:34:55.585010Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "iqhsS579LtEL",
    "outputId": "7cc3d723-9858-43a8-dcdf-37fcbef9456e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "results.loc['Support Vector Machine'] = {\r\n",
    "    'Count Vectors': accuracy1,\r\n",
    "    'WordLevel TF-IDF': accuracy2,\r\n",
    "    'N-Gram Vectors': accuracy3,\r\n",
    "    'CharLevel Vectors': accuracy4}"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:34:56.501558Z",
     "start_time": "2019-06-17T02:34:56.492592Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "go0bcKeILtEN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bagging Models"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "gLGxWK0yLtEO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "%%time\r\n",
    "# Bagging (Random Forest) on Count Vectors\r\n",
    "accuracy1 = train_model(RandomForestClassifier(n_estimators = 100), X_train_count, y_train, X_test_count)\r\n",
    "print('RF, Count Vectors    : %.4f\\n' % accuracy1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RF, Count Vectors    : 0.8360\n",
      "\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:35:20.807157Z",
     "start_time": "2019-06-17T02:34:56.823697Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "HR8aOytWLtEO",
    "outputId": "961d5bca-c1fe-46be-ba8c-2f6325d85901"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "%%time\r\n",
    "# Bagging (Random Forest) on Word Level TF IDF Vectors\r\n",
    "accuracy2 = train_model(RandomForestClassifier(n_estimators = 100), X_train_tfidf, y_train, X_test_tfidf)\r\n",
    "print('RF, WordLevel TF-IDF : %.4f\\n' % accuracy2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RF, WordLevel TF-IDF : 0.8280\n",
      "\n",
      "Wall time: 7.49 s\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:35:30.127233Z",
     "start_time": "2019-06-17T02:35:21.198110Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "zXcTCTEGLtET",
    "outputId": "e4336045-c508-4372-e102-35c559f9a195"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "%%time\r\n",
    "# Bagging (Random Forest) on Ngram Level TF IDF Vectors\r\n",
    "accuracy3 = train_model(RandomForestClassifier(n_estimators = 100), X_train_tfidf_ngram, y_train, X_test_tfidf_ngram)\r\n",
    "print('RF, N-Gram Vectors   : %.4f\\n' % accuracy3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RF, N-Gram Vectors   : 0.7890\n",
      "\n",
      "Wall time: 6.76 s\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:35:40.162390Z",
     "start_time": "2019-06-17T02:35:30.607944Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "EnvT8qvSLtEW",
    "outputId": "0c3a8fa0-7ee7-40ad-dc0e-85a8c3995733"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "%%time\r\n",
    "# Bagging (Random Forest) on Character Level TF IDF Vectors\r\n",
    "accuracy4 = train_model(RandomForestClassifier(n_estimators = 100), X_train_tfidf_ngram_chars, y_train, X_test_tfidf_ngram_chars)\r\n",
    "print('RF, CharLevel Vectors: %.4f\\n' % accuracy4)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RF, CharLevel Vectors: 0.7825\n",
      "\n",
      "Wall time: 25.1 s\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:36:07.640904Z",
     "start_time": "2019-06-17T02:35:40.542371Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "8jt-dTVELtEX",
    "outputId": "dc1113c9-b3f2-4d2e-f4d7-a5bcc98a020c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "results.loc['Random Forest'] = {\r\n",
    "    'Count Vectors': accuracy1,\r\n",
    "    'WordLevel TF-IDF': accuracy2,\r\n",
    "    'N-Gram Vectors': accuracy3,\r\n",
    "    'CharLevel Vectors': accuracy4}"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:36:08.104108Z",
     "start_time": "2019-06-17T02:36:08.097127Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "fVKeCH_VLtEZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Boosting Models"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "oyVz4Q6ILtEa"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "%%time\r\n",
    "# Gradient Boosting on Count Vectors\r\n",
    "accuracy1 = train_model(GradientBoostingClassifier(), X_train_count, y_train, X_test_count)\r\n",
    "print('GB, Count Vectors    : %.4f\\n' % accuracy1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GB, Count Vectors    : 0.7990\n",
      "\n",
      "Wall time: 29.5 s\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:36:37.197296Z",
     "start_time": "2019-06-17T02:36:08.451184Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "8wGvHTg-LtEb",
    "outputId": "dcc31f90-b0f8-4f5d-c835-25be80638e70"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "%%time\r\n",
    "# Gradient Boosting on Word Level TF IDF Vectors\r\n",
    "accuracy2 = train_model(GradientBoostingClassifier(), X_train_tfidf, y_train, X_test_tfidf)\r\n",
    "print('GB, WordLevel TF-IDF : %.4f\\n' % accuracy2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GB, WordLevel TF-IDF : 0.7960\n",
      "\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:36:52.852454Z",
     "start_time": "2019-06-17T02:36:37.714920Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "HJNwQf57LtEd",
    "outputId": "686abbc5-8745-4dca-c2e2-b665b9d19901"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "%%time\r\n",
    "# Gradient Boosting on Ngram Level TF IDF Vectors\r\n",
    "accuracy3 = train_model(GradientBoostingClassifier(), X_train_tfidf_ngram, y_train, X_test_tfidf_ngram)\r\n",
    "print('GB, N-Gram Vectors   : %.4f\\n' % accuracy3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GB, N-Gram Vectors   : 0.7365\n",
      "\n",
      "Wall time: 7.65 s\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:37:02.608379Z",
     "start_time": "2019-06-17T02:36:53.252355Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "iyPqLMgkLtEe",
    "outputId": "b7c87e04-f724-4ccf-e02e-28beb7e40654"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "%%time\r\n",
    "# Gradient Boosting on Character Level TF IDF Vectors\r\n",
    "accuracy4 = train_model(GradientBoostingClassifier(), X_train_tfidf_ngram_chars, y_train, X_test_tfidf_ngram_chars)\r\n",
    "print('GB, CharLevel Vectors: %.4f\\n' % accuracy4)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GB, CharLevel Vectors: 0.8020\n",
      "\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:39:14.314194Z",
     "start_time": "2019-06-17T02:37:03.039224Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "1KYdyatTLtEg",
    "outputId": "aa4f303e-76ff-47e6-a04f-7e311e1848ad"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "results.loc['Gradient Boosting'] = {\r\n",
    "    'Count Vectors': accuracy1,\r\n",
    "    'WordLevel TF-IDF': accuracy2,\r\n",
    "    'N-Gram Vectors': accuracy3,\r\n",
    "    'CharLevel Vectors': accuracy4}"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:39:14.683222Z",
     "start_time": "2019-06-17T02:39:14.675213Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "AC0hWO59LtEj",
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count Vectors</th>\n",
       "      <th>WordLevel TF-IDF</th>\n",
       "      <th>N-Gram Vectors</th>\n",
       "      <th>CharLevel Vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Na√Øve Bayes</th>\n",
       "      <td>0.8540</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>0.8180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.8520</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.8485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.8345</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.8210</td>\n",
       "      <td>0.8570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.7890</td>\n",
       "      <td>0.7825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.7990</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.7365</td>\n",
       "      <td>0.8020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Count Vectors  WordLevel TF-IDF  N-Gram Vectors  \\\n",
       "Na√Øve Bayes                    0.8540             0.860          0.8400   \n",
       "Logistic Regression            0.8520             0.873          0.8360   \n",
       "Support Vector Machine         0.8345             0.861          0.8210   \n",
       "Random Forest                  0.8360             0.828          0.7890   \n",
       "Gradient Boosting              0.7990             0.796          0.7365   \n",
       "\n",
       "                        CharLevel Vectors  \n",
       "Na√Øve Bayes                        0.8180  \n",
       "Logistic Regression                0.8485  \n",
       "Support Vector Machine             0.8570  \n",
       "Random Forest                      0.7825  \n",
       "Gradient Boosting                  0.8020  "
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T02:39:15.024279Z",
     "start_time": "2019-06-17T02:39:15.010319Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "b9fY4J7XLtEk",
    "outputId": "ea4a8ddf-5b37-4cb9-da79-1920e1967b03"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > ¬© 2021 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "_Pck1cuvLtDH",
    "mQCAUFWYLtDb",
    "OXwLriDpLtDq",
    "-2oNfajULtD4",
    "q1wYto68LtEE",
    "gLGxWK0yLtEO"
   ],
   "name": "IOD_Lab-9_7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('Env_DL': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "interpreter": {
   "hash": "d4cc69c2496bab24d490eb520a5bd7b6815fd7f954a293db4d3694c71cf4aecc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}